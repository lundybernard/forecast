{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame, Series, concat as pd_concat\n",
    "from pandera import DataFrameModel, Field\n",
    "\n",
    "from bat.sensors import sensor_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93439c64e6b5141",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxt = 1_000\n",
    "#maxt = 100\n",
    "sensors = sensor_array()\n",
    "raw_data = [next(sensors) for _ in range(maxt*3)]\n",
    "\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc64539fbeb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandera.typing import Index, DataFrame as dft\n",
    "\n",
    "# === Extract === #\n",
    "\n",
    "raw_data_columns_type = Literal['time', 'channel', 'value']\n",
    "raw_data_channel_type = Literal['anomaly', 'blue', 'red']\n",
    "raw_data_values_type = bool | int\n",
    "\n",
    "raw_data_type = list[tuple[int, raw_data_channel_type, raw_data_values_type]]\n",
    "\n",
    "\n",
    "class RawDataDF(DataFrameModel):  # Extract\n",
    "    time: int = Field(\n",
    "        title='time',\n",
    "        description='time-stamp in integer format',\n",
    "        ge=0,\n",
    "    )\n",
    "    channel: str = Field(\n",
    "        title='channel',\n",
    "        description='designates the channel this value came from',\n",
    "        isin=('red', 'blue', 'anomaly'),\n",
    "    )\n",
    "    value: int = Field(\n",
    "        title='value',\n",
    "        description='the value returned from the sensor channel',\n",
    "    )\n",
    "    \n",
    "    class Config:\n",
    "        coerce = True\n",
    "\n",
    "\n",
    "class SensorData:\n",
    "    \n",
    "    def __init__(self, raw_data: raw_data_type):\n",
    "        self.raw_data = raw_data\n",
    "    \n",
    "    @property\n",
    "    def dataframe(self) -> RawDataDF:\n",
    "        return RawDataDF(\n",
    "            DataFrame(self.raw_data, columns=['time', 'channel', 'value'])\n",
    "        )\n",
    "    \n",
    "\n",
    "sd = SensorData(raw_data=raw_data)\n",
    "\n",
    "sd.dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff6c48d9e2adc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Transform === #\n",
    "\n",
    "def normalized_sensor_field() -> Field:\n",
    "    return Field(ge=0, le=1)\n",
    "\n",
    "def normalized_anomaly_field() -> Field:\n",
    "    return Field(isin=(0.0, 1.0))\n",
    "\n",
    "\n",
    "class NormalizedAnomalyDF(DataFrameModel):\n",
    "    anomaly: float = normalized_anomaly_field()\n",
    "\n",
    "class NormalizedBlueDF(DataFrameModel):\n",
    "    blue: float = normalized_sensor_field()\n",
    "\n",
    "class NormalizedRedDF(DataFrameModel):\n",
    "    blue: float = normalized_sensor_field()\n",
    "    \n",
    "\n",
    "class NormalizedChannelsDF(\n",
    "    NormalizedAnomalyDF, \n",
    "    NormalizedBlueDF, \n",
    "    NormalizedRedDF, \n",
    "    DataFrameModel,\n",
    "):\n",
    "    index: Index[int] = Field(ge=1)\n",
    "    \n",
    "    \n",
    "class NormalizedData:\n",
    "    \n",
    "    def __init__(self, raw_data_df: dft[RawDataDF]):\n",
    "        self.raw_data_df = raw_data_df\n",
    "        \n",
    "    @property\n",
    "    def dataframe(self) -> NormalizedChannelsDF:\n",
    "        df = pd_concat(\n",
    "            [\n",
    "                self.normalized_anomaly, \n",
    "                self.normalized_blue, \n",
    "                self.normalized_red,\n",
    "            ], \n",
    "            axis=1\n",
    "        )\n",
    "        return NormalizedChannelsDF(df.dropna())\n",
    "    \n",
    "    @property\n",
    "    def normalized_anomaly(self) -> NormalizedAnomalyDF:\n",
    "        if 'anomaly' in self.data_by_channel.columns:\n",
    "            return (\n",
    "                self.data_by_channel['anomaly']\n",
    "                .astype(float).replace(True, 1).fillna(0)\n",
    "            )\n",
    "        else:  # no anomaly column data provided\n",
    "            return NormalizedAnomalyDF(\n",
    "                Series(0.0, index=self.data_by_channel.index, name='anomaly')\n",
    "                .to_frame()\n",
    "            )\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def normalized_blue(self) -> NormalizedBlueDF:\n",
    "        # Normalize the blue channel to fill missing values\n",
    "        return self.data_by_channel['blue'].astype(float) / 1000\n",
    "\n",
    "    @property\n",
    "    def normalized_red(self) -> NormalizedRedDF:\n",
    "        return self.data_by_channel['red'].astype(float) / 100\n",
    "        \n",
    "    @property\n",
    "    def data_by_channel(self) -> DataFrame:\n",
    "        return self.raw_data_df.pivot(\n",
    "            index='time', columns='channel', values='value'\n",
    "        )\n",
    "\n",
    "    \n",
    "normalized_data = NormalizedData(raw_data_df=sd.dataframe)\n",
    "normalized_data.dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd72638539b6477",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandera.typing import DataFrame as dft\n",
    "\n",
    "\n",
    "class LaggedDatasetDF(DataFrameModel):\n",
    "    anomaly: float = normalized_anomaly_field()\n",
    "    blue: float = normalized_sensor_field()\n",
    "    red: float = normalized_sensor_field()\n",
    "    anomaly_t_1: float = normalized_anomaly_field()\n",
    "    blue_t_1: float = normalized_sensor_field()\n",
    "    red_t_1: float = normalized_sensor_field()\n",
    "    anomaly_t_2: float = normalized_anomaly_field()\n",
    "    blue_t_2: float = normalized_sensor_field()\n",
    "    red_t_2: float = normalized_sensor_field()\n",
    "    anomaly_t_3: float = normalized_anomaly_field()\n",
    "    blue_t_3: float = normalized_sensor_field()\n",
    "    red_t_3: float = normalized_sensor_field()\n",
    "    \n",
    "    class Config:\n",
    "        strict = True\n",
    "        coerce = True\n",
    "\n",
    "\n",
    "class LaggedData:  # Transform\n",
    "    \n",
    "    def __init__(self, df: dft[NormalizedChannelsDF]):\n",
    "        self.data = df\n",
    "        self.n_in = 3\n",
    "        self.n_out = 1\n",
    "        \n",
    "    @property\n",
    "    def dataframe(self) -> LaggedDatasetDF:\n",
    "        return LaggedDatasetDF(\n",
    "            pd_concat((self.data, self.input_columns), axis=1).dropna()\n",
    "        )\n",
    "    \n",
    "    @property\n",
    "    def input_columns(self) -> LaggedDatasetDF:\n",
    "        # input sequence (t-n, ... t-1)\n",
    "        cols = pd_concat(\n",
    "            [\n",
    "                self.data.shift(i) \n",
    "                for i in range(self.n_in, 0, -1)\n",
    "            ], \n",
    "            axis=1\n",
    "        )\n",
    "        cols.columns = self.input_column_names\n",
    "        return cols.dropna()\n",
    "        \n",
    "    @property\n",
    "    def input_column_names(self) -> list[str]:\n",
    "        return [\n",
    "            f'{col}_t_{i}' \n",
    "            for i in range(self.n_in, 0, -1)\n",
    "            for col in self.data.columns\n",
    "        ]\n",
    "    \n",
    "    \n",
    "ld = LaggedData(df=normalized_data.dataframe)\n",
    "print(f'{ld.input_columns=}')\n",
    "ld.dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1a55c84081c9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "    \n",
    "    def __init__(self, raw_data: raw_data_type):\n",
    "        self.raw_data = raw_data\n",
    "        \n",
    "    @property\n",
    "    def lagged_df(self) -> LaggedDatasetDF:\n",
    "        return self.lagged_data.dataframe\n",
    "    \n",
    "    @property\n",
    "    def lagged_data(self) -> LaggedData:\n",
    "        return LaggedData(self.normalized_df)\n",
    "    \n",
    "    @property\n",
    "    def normalized_df(self) -> NormalizedChannelsDF:\n",
    "        return self.normalized_data.dataframe\n",
    "    \n",
    "    @property\n",
    "    def normalized_data(self) -> NormalizedData:\n",
    "        return NormalizedData(self.sensor_df)\n",
    "        \n",
    "    @property\n",
    "    def sensor_df(self) -> RawDataDF:\n",
    "        return self.sensor_data.dataframe\n",
    "    \n",
    "    @property\n",
    "    def sensor_data(self) -> SensorData:\n",
    "        return SensorData(self.raw_data)\n",
    "\n",
    "\n",
    "prep = Preprocessor(raw_data=raw_data)\n",
    "prep.lagged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f146c186b6f4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_raw_data(df: RawDataDF):\n",
    "    df.columns = ['time', 'channel', 'value']\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    channels = df[df['channel'].isin(['red', 'blue'])][\n",
    "        'channel'].unique()  # getting unique channels excluding 'anomaly'\n",
    "    \n",
    "    for channel in channels:\n",
    "        channel_data = df[df['channel'] == channel]\n",
    "        plt.plot(channel_data['time'], channel_data['value'], label=channel)\n",
    "    \n",
    "    anomalies = df[df['channel'] == 'anomaly']\n",
    "    for i in range(len(anomalies)):\n",
    "        plt.fill_between(\n",
    "            [anomalies.iloc[i, 0] - 1, anomalies.iloc[i, 0]],\n",
    "            [0, 0],\n",
    "            [df['value'].max(), df['value'].max()],\n",
    "            color='gray',\n",
    "            alpha=0.5\n",
    "            )\n",
    "    \n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Sensor Value')\n",
    "    plt.title('Sensor Data Over Time')\n",
    "    plt.legend()  # add a legend for each channel\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Too slow\n",
    "graph_raw_data(sd.dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21925b0bb4f7d900",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195f0ed2aab1a795",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandera.typing import Index\n",
    "\n",
    "def normalized_sensor_field() -> Field:\n",
    "    return Field(ge=0, le=1)\n",
    "\n",
    "def normalized_anomaly_field() -> Field:\n",
    "    return Field(isin=(0.0, 1.0))\n",
    "\n",
    "\n",
    "\n",
    "class NormalizedChannelsDF(DataFrameModel):\n",
    "    index: Index[int] = Field(ge=1)\n",
    "    anomaly: float = normalized_anomaly_field()\n",
    "    blue: float = normalized_sensor_field()\n",
    "    red: float = normalized_sensor_field()\n",
    "    \n",
    "\n",
    "\n",
    "def preprocess(input_df: RawDataDF) -> NormalizedChannelsDF:\n",
    "    # remove rows with Negative values\n",
    "    input_df.drop(input_df[input_df['value'] < 0].index, inplace=True)\n",
    "    \n",
    "    d2 = input_df.pivot(index='time', columns='channel', values='value')\n",
    "    # cleanup pivoted dataframe\n",
    "    # Add anomaly channel if it is missing\n",
    "    \n",
    "    # Convert Anomaly channel to binary float\n",
    "    if 'anomaly' in d2.columns:\n",
    "        d2['anomaly'] = d2['anomaly'].astype(float).replace(True, 1).fillna(0)\n",
    "    else:\n",
    "        d2['anomaly'] = 0.0\n",
    "    \n",
    "    # Normalize and interpolate the blue channel to fill missing values\n",
    "    d2['blue'] = d2['blue'].astype(float)\n",
    "    d2['blue'] /= 1000\n",
    "    d2['blue'] = d2['blue'].interpolate(method='linear', limit_direction='forward')\n",
    "    \n",
    "    # Normalize red channel... figure out missing values\n",
    "    d2['red'] = d2['red'].astype(float)\n",
    "    if d2['red'].any() < 0:\n",
    "        print(f'low {d2[\"red\"]=}')\n",
    "    d2['red'] /= 100\n",
    "    if d2['red'].any() < 0:\n",
    "        print(f'normalized low {d2[\"red\"]=}')\n",
    "        \n",
    "    # Drop NaN values\n",
    "    d2.dropna(inplace=True)    \n",
    "    \n",
    "    # Type the pivoted data\n",
    "    d2.index = d2.index.astype('int32')\n",
    "    \n",
    "    \n",
    "    return NormalizedChannelsDF(d2)\n",
    "\n",
    "\n",
    "d2 = preprocess(data)\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7eeea4b1c29fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUG REPORT\n",
    "# Fails\n",
    "GenericField: float = Field(ge=0)\n",
    "\n",
    "class BadModelDF(DataFrameModel):\n",
    "    field: float = GenericField\n",
    "    field_1: float = GenericField\n",
    "    \n",
    "    class Config:\n",
    "        strict = True\n",
    "\n",
    "# Works\n",
    "def generic_field() -> Field:\n",
    "    return Field(ge=0)\n",
    "\n",
    "class GoodModelDF(DataFrameModel):\n",
    "    field: float = generic_field()\n",
    "    field_1: float = generic_field()\n",
    "    \n",
    "    class Config:\n",
    "        strict = True\n",
    "        \n",
    "df = DataFrame({'field': [0.0, 0.1], 'field_1': [0.2, 0.3]})\n",
    "\n",
    "print(GoodModelDF(df))\n",
    "\n",
    "BadModelDF.validate(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807320cf3a38675f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lagged_dataset(df: dft[NormalizedChannelsDF]) -> LaggedDatasetDF:\n",
    "    \"\"\"\n",
    "    Create a lagged Dataset.\n",
    "\n",
    "    Parameters:\n",
    "    df - your dataframe\n",
    "    n_in - your input sequence length\n",
    "    n_out - your output sequence length\n",
    "    dropnan - to drop or not to drop NaN values from the DataFrame\n",
    "    \"\"\"\n",
    "    n_in = 3\n",
    "    n_out = 1\n",
    "    cols, names = list(), list()\n",
    "    \n",
    "    \n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [f'{col}_t_{i}' for col in df.columns]\n",
    "    \n",
    "    # forecast sequence (t, t+1, ... t+n)  # Unused\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        names += [f'{col}{f\"_t{i}\" if i else \"\"}' for col in df.columns]\n",
    "\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    agg = agg[[\n",
    "        \"anomaly_t_3\", \"blue_t_3\", \"red_t_3\", \n",
    "        \"anomaly_t_2\", \"blue_t_2\", \"red_t_2\",\n",
    "        \"anomaly_t_1\", \"blue_t_1\", \"red_t_1\",\n",
    "        \"anomaly\", \"blue\", \"red\",\n",
    "    ]]\n",
    "    # drop rows with NaN values\n",
    "    agg.dropna(inplace=True)\n",
    "\n",
    "    return LaggedDatasetDF(agg)\n",
    "\n",
    "\n",
    "d2_lagged = create_lagged_dataset(d2)\n",
    "d2_lagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e620e0aaf0c81437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert channels to columns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Declare features/predictors and target variable\n",
    "X = d2_lagged.drop('anomaly', axis=1)\n",
    "y = d2_lagged['anomaly']\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=123\n",
    "    )\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Replacing infinities with NaN\n",
    "#X_train = X_train.replace([np.inf, -np.inf], np.nan)\n",
    "#X_test = X_test.replace([np.inf, -np.inf], np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a277e559a455f3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# Create model \n",
    "model = RandomForestClassifier(n_estimators=100, random_state=123)\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a0bf2e186f56a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cbaf86e4de8490",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c1775729496a5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997b3b89a1f1a013",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata = [next(sensors) for _ in range(30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7badafee6a477a",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata.append(next(sensors))\n",
    "\n",
    "newdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa0eb867a4d4631",
   "metadata": {},
   "outputs": [],
   "source": [
    "nd = RawDataDF(DataFrame(newdata, columns=['time', 'channel', 'value']))\n",
    "#nd.columns = ['time', 'channel', 'value']\n",
    "print(f'{nd=}')\n",
    "\n",
    "nd2 = preprocess(nd)\n",
    "print(nd2)\n",
    "nd2.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea83b5cde013cbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame(newdata, columns=['time', 'channel', 'value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dee7c1f04ece54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame(newdata, columns=['time', 'channel', 'value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c13f08152588b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nd2_lagged = create_lagged_dataset(nd2, n_in=3, n_out=1)\n",
    "nd2_lagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6317e341db466563",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def create_lagged_dataset(df, n_in=3, n_out=1, dropnan=True):\n",
    "    \"\"\"\n",
    "    Create a lagged Dataset.\n",
    "\n",
    "    Parameters:\n",
    "    df - your dataframe\n",
    "    n_in - your input sequence length\n",
    "    n_out - your output sequence length\n",
    "    dropnan - to drop or not to drop NaN values from the DataFrame\n",
    "    \"\"\"\n",
    "    n_vars = df.shape[1]\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [f'{col}(t-{i})' for col in df.columns]\n",
    "    \n",
    "    print(f'\\n{cols=}, {names=}')\n",
    "    # forecast sequence (t, t+1, ... t+n)  # Unused\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        names += [f'{col}({f\"t-{i}\" if i else \"t\"})' for col in df.columns]\n",
    "\n",
    "    print(f'\\n{cols=}, {names=}')\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    "'''\n",
    "\n",
    "d2_lagged = create_lagged_dataset(nd2, n_in=3, n_out=1)\n",
    "d2_lagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5600a48ceb0abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df: LaggedDatasetDF) -> DataFrame:\n",
    "    X = df.drop('anomaly', axis=1)\n",
    "    y_pred = model.predict(X=X)\n",
    "    print(f'{y_pred}')\n",
    "    \n",
    "    lag = 3\n",
    "    predictions_df = DataFrame(y_pred, columns=['anomaly_predicted'])\n",
    "    predictions_df.index = X.index\n",
    "    return predictions_df\n",
    "\n",
    "predictions_df = predict(nd2_lagged)\n",
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25382c3a07295b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(ax, X, Y_pred):\n",
    "    ax.clear()\n",
    "    # Plot the ground truth\n",
    "    ax.plot(\n",
    "        X.index,\n",
    "        X['blue'].values,\n",
    "        label='blue',\n",
    "        color='b'\n",
    "        )\n",
    "    ax.plot(\n",
    "        X.index,\n",
    "        X['red'].values,\n",
    "        label='red',\n",
    "        color='r',\n",
    "    )\n",
    "    ax.plot(\n",
    "        X.index,\n",
    "        X['anomaly'],\n",
    "        label='anomaly(actual)',\n",
    "        color='y',\n",
    "    )\n",
    "    ax.plot(\n",
    "        Y_pred.index,\n",
    "        Y_pred['anomaly_predicted'],\n",
    "        label='Anomaly Predicted',\n",
    "        color='g',\n",
    "    )\n",
    "    # Visual settings of the graph\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "    ax.set_title('Ground Truth vs Prediction')\n",
    "    ax.set_xlabel('Timestamp')\n",
    "    ax.set_ylabel('Anomaly Detection')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "figure, ax = plt.subplots()\n",
    "plot_result(ax, nd2, predictions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb24def2895d119f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4199182d3de3331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Loop\n",
    "newdata.append(next(sensors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64d8a5a3851e5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_prediction(newdata: DataFrame, ax):\n",
    "    nd = DataFrame(newdata)\n",
    "    nd.columns = ['time', 'channel', 'value']\n",
    "    #print(f'{nd=}')\n",
    "    \n",
    "    nd2 = preprocess(nd)\n",
    "    #print(nd2)\n",
    "    #nd2.plot()\n",
    "    nd3 = create_lagged_dataset(nd2)\n",
    "    X = nd3.drop('anomaly', axis=1)\n",
    "    y_pred = model.predict(X=X)\n",
    "    print(f'{y_pred}')\n",
    "    combine_df = nd3.copy()\n",
    "    combine_df['anomaly_predicted'] = y_pred \n",
    "    \n",
    "    lag = 3\n",
    "    predictions_df = DataFrame(y_pred, columns=['anomaly_predicted'])\n",
    "    print(f'{predictions_df.head()=}')\n",
    "    predictions_df.index += X.index\n",
    "    print(f'{predictions_df.head()=}')\n",
    "    \n",
    "    #plot_result(ax, nd2, predictions_df)\n",
    "    plot_result(ax, nd2, predictions_df)\n",
    "\n",
    "    \n",
    "figure, ax = plt.subplots()\n",
    "graph_prediction(newdata, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876eefa2c197300",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "for _ in range(100):\n",
    "    newdata.append(next(sensors))\n",
    "    graph_prediction(newdata, ax)\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee7e788b39bb922",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2f11cae8ab26ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6060b84896c9bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nd = DataFrame(newdata)\n",
    "nd.columns = ['time', 'channel', 'value']\n",
    "#print(f'{nd=}')\n",
    "\n",
    "nd2 = preprocess(nd)\n",
    "#print(nd2)\n",
    "nd2.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c659b3e32d45183",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
